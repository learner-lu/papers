
# hugescope

- 题目: Taming Hot Bloat Under Virtualization with HugeScope
- 会议: USENIX ACT'24
- 视频: [USENIX ATC '24 - Taming Hot Bloat Under Virtualization with HUGESCOPE](https://www.youtube.com/watch?v=30Y5-sBz1Wo)
- 代码: [hugescope-atc24-ae](https://github.com/TELOS-syslab/hugescope-atc24-ae)

> [!NOTE]
> 本文作者和 [vTMM](./vtmm.md) 的作者是一个组的
>
> 本文主要是针对虚拟化大页访问偏度的优化, 和分层内存管理关系不大

## 研究问题

> 论文试图解决的具体问题是什么?该问题的核心挑战是什么?

随着虚拟机(VM)内存占用的增加,大页面被用来减轻TLB的压力.这带来了显着的性能提升(在各种基准测试中提升了11%-53%),原因有两个:(1)它增加了TLB覆盖范围,降低了TLB丢失率;(2)减少了页面遍历的开销.

研究发现对于许多工作负载来说,在其执行期间,对大页的基页(即4KB页)的访问是高度倾斜的;一些基页被频繁访问,而另一些基页则很少被访问或根本不被访问. 而本文试图解决这种虚拟化环境下使用大页(huge pages)导致的"**热膨胀**"(hot bloat)问题. 即由于对少数基本页面的访问存在偏差,系统会错误地将整个大页面分类为热门页面.

> PRISM 包括迄今为止对这一现象最广泛的研究.对于一组 35 个基准测试,包括一整套 PARSEC、SPEC、三个 GPU 基准测试和多个服务器基准测试,69% 的基准表现出这种访问偏度.

当访问集中于大页中的少数基本页(如 4KB 页)时,虚拟机管理程序会错误地将整个大页标记为"热",从而导致虚拟化中的多项关键技术(如分层内存管理和页共享)效率下降. 之前解决热膨胀的工作要么需要硬件修改,要么针对特定场景,并且不适用于虚拟机管理程序.本文提出的 HugeScope,是一个轻量级、有效且通用的系统,它解决了基于商用硬件的虚拟化下的热膨胀问题. 

## 局限性分析

> 现有研究的主要局限或缺点是什么?

现有研究在应对虚拟化环境中的"热膨胀"问题时存在几个主要局限或缺点:

1. **需要硬件修改**:一些解决方案(如 PRISM 和 RainBow)依赖于硬件更改,限制了它们在现有商用硬件上的适用性,增加了部署成本和复杂性.

2. **针对特定场景设计**:许多现有方法只能在特定场景下有效.例如,Memtis 使用处理器事件采样(PEBS)跟踪内存访问,但这种方法无法应用于通用虚拟化环境,尤其是因为硬件限制使得管理程序无法可靠地监控来宾虚拟机的内存访问.

3. **监控精度问题**:一些方法,如 Thermostat,采用采样技术来跟踪内存访问,这种采样方法往往不够精确,导致系统在进行内存管理决策时出现次优表现.

4. **高开销**:传统方法(如使用页故障或分裂大页的机制)会带来显著的性能开销,尤其是在虚拟化环境中,频繁的页表修改可能导致大量的虚拟机退出,从而严重影响系统性能.

## 解决方案

> 动机

直观上,为了获得大页内的访问偏度,可以**将大页拆分为基页**,并使用基于分页的机制跟踪对这些基页的内存访问.访问跟踪期结束后,基页可以合并回大页,以继续享受大页的性能优势

但是,**执行拆分和合并的开销是不可接受的**. 这两个操作都需要使虚拟机的 EPT 无效.当再次访问这些页面时(对于这些活动页面来说,在不久的将来),这会导致昂贵的 VM 退出来重建 EPT

> 对比评估了 split_huge_page() 和 collapse_huge_page() 两个函数的开销 145ns 和 250ns

![20241110232341](https://raw.githubusercontent.com/learner-lu/picbed/master/20241110232341.png)

因此必须在很高的页面拆分/合并开销的情况下实现轻量级、精确的基页粒度内存访问跟踪

本文的动机来自于两个观察发现

1. EPT 很少修改.在构建扩展页表项(EPTE)之后,管理程序很少对其进行修改.这是因为来宾页表 (GPT) 吸收了来自应用程序的所有页表修改请求(例如,映射和取消映射页面、更改权限位). EPT的访问只会出现在hypervisor管理请求中.

   下图可知绝大部分页表的修改都发生在 GPT 中

   ![20241110232116](https://raw.githubusercontent.com/learner-lu/picbed/master/20241110232116.png)

2. 即使虚拟机管理程序访问/修改 EPT,它也总是通过一些稳定的接口来实现.
   - 它们通过少量函数(例如 KVM 中的 11 个)访问/修改 EPT. 
   - 这套接口稳定.对于 KVM 和 Xen,在过去 9 年和 7 年中分别没有向该集合添加或删除任何功能.

---

Hugescope 的设计如下, 主要分为三个部分

1. 页面访问追踪
2. 轻量级页表拆分和合并来获取热大页的访问倾斜度
3. 考虑页面热度和偏斜度的默认页面大小策略来解决热膨胀问题

> 以及模块化的接口

![20241111003336](https://raw.githubusercontent.com/learner-lu/picbed/master/20241111003336.png)

### 内存访问追踪

跟踪内存访问的最直接方法是通过页面错误. 即通过设置内存页面的权限位(如将一个页面标记为只读或不可访问),当程序试图进行相应的内存操作时,会产生一个页面错误.操作系统或监控程序可以捕获这个页面错误,记录访问行为,并选择是否恢复页面的原始权限,继续程序执行或进行其他处理. 但是这种方式处理页面错误的成本很高(并且在虚拟化环境中变得更加昂贵),因此基于页面错误的方法仅限于跟踪内存访问的小样本

> [telescope](./telescope.md) 中比较详细的对比了几种页面追踪的方式, 除了页面错误还有页表扫描, 区间采样和硬件计数

现代硬件在每个页表条目中包含一个访问/脏(A/D)位,以方便内存访问跟踪.不幸的是,这种方法无法跟踪对大页内基页的访问,因此无法获取访问倾斜度信息.处理器基于事件的采样.

> [!IMPORTANT]
> 最近的系统使用名为处理器基于事件的采样(PEBS)的硬件功能来跟踪内存访问.
> 
> PEBS将触发条件(例如,每1000个LLC未命中)和PEBS缓冲区作为输入,由存储在名为IA32DSAREA的模型特定寄存器中的虚拟地址指定.每当触发条件满足时,PEBS就查阅 IA32_DS_AREA 来获取PEBS缓冲区的虚拟地址,并将进程ID和访问的虚拟地址写入PEBS缓冲区.
> 
> 不幸的是,使用当前的硬件,虚拟机管理程序不可能使用PEBS监视来宾.这一限制是因为每个CPU只有一个 IA32_DS_AREA 寄存器,该寄存器由VM和虚拟机管理程序共享.当VM执行触发指定条件时,硬件记录到VM的虚拟地址(IA32_DS_AREA 中存储的地址)而不是hypervisorfis地址空间.这可能会损坏虚拟机(因为虚拟机不希望进行此类写入),并使虚拟机管理程序难以访问结果,因为它们驻留在虚拟机的地址空间中

因此作者提出了**两阶段内存访问跟踪**:

- **粗略阶段**:HugeScope 使用 EPT 中的访问和脏位(A/D bits)来跟踪所有页的访问频率和最近访问时间,而无需进行昂贵的页表分裂操作.这个阶段的目标是识别哪些大页是"热"的.
- **精细阶段**:在识别出热大页后,HugeScope 仅分裂这些大页,跟踪其每个基本页的访问情况,以获取更详细的访问模式(如访问倾斜性).在这一阶段结束后,系统将这些基本页重新合并为大页,以继续利用大页带来的性能优势.

由于对管理程序元数据的修改成本高昂,当前页面拆分/合并所产生的开销是不可接受的.为了克服这一挑战,在细路径阶段,**HugeScope仅修改内存访问跟踪下的大页的EPT(具体而言,最后一级页表中的条目)以执行拆分和合并操作,而不执行任何修改到元数据结构**.

这种方法会导致 EPT 和虚拟机管理程序元数据之间**暂时不一致**; 当HugeScope拆分页表时(在精细路径阶段的开始),不一致会发生;当HugeScope合并页表时(在精细路径页面的末尾),不一致就会消失.这种方法很有效,因为管理程序很少访问和修改 EPT(第 3.3.2 节).因此,在大多数情况下,虚拟机管理程序永远不会观察到这种不一致(因为它不访问或修改 EPT).因此,在几乎所有情况下,HugeScope不需要采用特殊的回退机制来解决不一致问题

## 实验

> 实验是如何设计的? 结果如何证明了论文方法的有效性?是否有对比实验?

本文的实验通过对 HugeScope 的性能、内存跟踪效率、以及与现有方法的对比来验证其有效性.实验设计包括以下几个方面:

1. **内存访问跟踪效率**:
   - 比较 HugeScope 的两阶段内存访问跟踪机制与现有方法(如基于页分裂的扫描、采样扫描和 PEBS(处理器事件采样))的开销与精确度.实验设置了不同的内存工作集规模,监测 Redis 等应用的内存访问情况,并分析跟踪的开销和准确度.

2. **页分裂与合并的性能影响**:
   - 通过运行顺序读取和写入微基准测试,评估 HugeScope 的虚拟化友好型页分裂和合并机制与传统 Linux 页表操作的性能开销.实验中测量了因页表修改引发的 VM 退出次数和整体性能下降情况.

3. **与现有方案的对比**:
   - 在分层内存管理(HS-TMM)和页共享(HS-Share)场景下,HugeScope 与现有系统(如 vTMM-Huge、vTMM-Base、Ingens 和 Linux KSM)进行了对比.实验使用不同的内存配置和工作负载(如 Redis、MongoDB、Graph500 等),测量各方法的性能提升、内存节省效果和平均延迟.

### 实验结果

1. **内存访问跟踪效率**:
   - HugeScope 在跟踪内存访问时,比基于页分裂的扫描显著降低了性能开销,平均仅为 3.04%,而页分裂扫描可达 25% 的性能损失.相比于采样扫描和 PEBS,HugeScope 提供了更高的精确度,并能够快速识别访问倾斜.

2. **页分裂与合并的性能影响**:
   - HugeScope 的页分裂与合并机制显著减少了 VM 退出次数和性能损失.在工作集规模为 16GB 时,传统 Linux 分裂/合并操作导致性能下降高达 25.39%,而 HugeScope 的优化机制将其减少至 1.5%.

3. **对比实验**:
   - **分层内存管理(HS-TMM)**:HugeScope 支持的 HS-TMM 在高内存压力下显著优于 vTMM-Huge 和 vTMM-Base,性能提升最多达 61%.与传统的基于采样的 Thermostat 方法相比,HS-TMM 能更准确地跟踪热页并优化内存布局.
   - **页共享系统(HS-Share)**:HS-Share 在内存节省和性能之间取得了良好的平衡,节省了 41% 的内存,同时仅有 3.6% 的性能损失,而 Ingens 由于热膨胀问题仅节省了 1.28% 的内存.

### 证明有效性

通过对比实验结果可以看出,HugeScope 显著降低了内存访问跟踪的开销,提升了内存管理系统的性能,并有效解决了热膨胀问题.与现有方案相比,HugeScope 的改进在多种应用场景下表现出了优越性,证明了其方法的有效性和适用性.

## 个人思考

> 阅读论文时,有没有引发你思考出新的问题或有待解决的挑战?

作者很详细的讨论的 PEBS 的原理以及为什么虚拟化中不能使用 PEBS, 可以作为论述的借鉴参考

依然使用的是 EPT 扫描的方式, 但是 [vTMM](./vtmm.md) 提到 EPT 的方式没有 GPT 高效

## 摘抄