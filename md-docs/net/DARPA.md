
# The Design Philosophy of the DARPA Internet Protocols

> [acm dl](https://dl.acm.org/doi/abs/10.1145/52324.52336) 1988 SIGCOMM

## 论文基本情况
- 论文标题:    The Design Philosophy of the DARPA Internet Protocols
- 发表会议/期刊: Proc. SIGCOMM '88, Computer Communication Review Vol. 18, No. 4, August 1988, pp. 106–114

## 论文摘要(Abstract)
早期的互联网协议簇 TCP/IP由DARPA开发,现已广泛用于军事和商业系统.本文不关注网络协议如何实现的,而是关注早期网络协议的设计思路.
## 研究动机(Motivation/Introduction)
本文不是一篇传统的学术科学研究性质的论文,而是对互联网架构以及网络协议的产生和设计的历史回顾与思考,与此同时对设计历史的理解也为当前的设计扩展提供了参考原型,现代 ISO 协议的种种特性比如无连接配置的设计被互联网套件的历史所影响.本文对互联网架构的原始目标进行了讨论,分析了这些目标与协议的重要特征之间的关系.
## 相关工作(Related Work)
本文是对互联网历史以及架构设计的回顾,相关工作集中于早期的架构设计方案以及协议方案.
## 解决方案(Solution)
DARPA 的初始任务是开发一种有效的技术来复用现有互连网络.在设计之初就有考虑过多种类型的网络以及未来的网络结构设计,希望将多个单独的实体统一加入到一个统一的网络当中,最终选择使用分组交换技术作为互联网架构的底层传输手段,通过一系列分组交换通信设施例如网关,将许多不同的网络连接在一起.

网络设计的目标是有顺序的,不同的场景下优先级不同.例如军事环境下优先考虑的是集中一切可用资源并以可操作的方式快速部署它们,而并不关心所用资源的详细核算.商业环境下则恰恰相反.

其中网络的首要目的是保证通信,除非所有的物理传输通路全部被切断.同时这种架构不保证发送方和接收方的信息同步问题,只要没有全局故障,该架构总是可以处理局部的短暂故障.为了达成这个目标,网络需要维护信息状态避免丢失.但由于复制的分布式特性,确保稳健复制的算法本身很难构建,并且很少有具有分布式状态信息的网络提供任何类型的故障保护,期望每一个节点都同步的复制信息十分困难,因此网络转而选择将同步的任务交给主机端和服务端.进而引出关于  fate-shareing 的概念,可以防止任意数量的中间故障,而复制只能防止一定数量的中间故障(小于复制副本的数量).比分布式的复制更容易设计与实现.

第二个目标是希望网络架构可以支持多种设备类型.但实际上考虑到不同的服务对于延迟/带宽/可靠性的敏感度要求不同,因此试图将所有这些服务的支持构建到一个协议中是很困难的,单一的 TCP 协议无法满足所有需求.因此将 TCP/IP 拆分为传输可靠数据流的 TCP 和传输数据包的 IP 协议.除此之外设计的网络结构很难去满足各种类型的服务,特定的网络结构只能满足某一类服务的需求.
网络结构的设计十分成功,因为它仅仅做出了一些关键性的假设

1. 可以传输数据包或数据报
2. 包大小适中
3. 传输的可靠性合理
4. 合理的寻址方式

同时把更多的设计空间留给各自的网络结构,这样可以避免在每个网络和主机网络接口都需要考虑大量复杂的设计以适应各种类型的网络结构.可以在工程上完成很简洁的网络接口实现.

接着讲了一些次要目标,包括前文提到的

1. 分布式
2. 成本效益
3. 主机易实现(主机端接口设计)
4. 可以计算流量


当时看来很多尚未解决的问题(比如路由选择算法,流量计算)现如今都已经有了成熟的解决方案,大部分的协议(TCP HTTP SMTP)也都有数据包恢复机制以减小网络流量;主机端网络协议实现也已经由操作系统内核网络协议栈 + 网卡 + 网卡驱动负责了,socket接口也还算简洁.

除此之外数据包恢复机制十分重要,如果互联网协议不提供数据包恢复机制,那么在数据包丢失时需要重新传输数据包,可能导致数据包多次经过中间网络,而如果有网络层面的恢复机制,就可以避免这种重复传输.例如大文件被分成多个小数据包来传输,在传输过程中,某个数据包丢失了,如果该协议有数据包恢复机制,服务器可以仅要求重新传输丢失的那个数据包,而不是整个文件.这将减少网络上的流量

由于最开始网络主机数量有限所以可以接受,但随着互联网规模的扩张,主机数量增多,同时由于最初 fate-shareing 的设计,部分节点的失联不会导致整体稳定性的破坏,传输节点不记录关键信息状态,因此计算压力给到了个体主机本身算法(host-resident mechanism)的实现.

网络架构设计是一个很笼统的概念,具体到实际应用的网络结构以及采用的网络协议,不同的架构和协议在差距很大,需要具体分析.于此同时如何为为网络的实现者提供有效的指导以满足不同服务也十分重要.对于性能的约束不应该被写入标准规范,但同时架构设计与性能的关系又很复杂.

数据报的设计很巧妙,既完成了网络设计的基本任务,同时也给了网络协议实现很大的操作空间.但一个经典的误区是"数据报的动机是支持更高级别的服务",理由是应用程序需要的传输服务是数据报服务.这种说法仅适用于简单数据报可以支持的服务,但实际上大部分服务由于需要考虑差错/延迟/可靠性,所采用了要比数据块复杂得多的设计,所以这个说法是错误的.

最后介绍了 TCP 设计的构想,最初选择字节传输

1. 在数据流中插入控制信息(实现复杂)
2. 可以根据主机配置被拆为更小的包(交给IP处理)
3. 整合多个小TCP包,方便远程登陆的字符传输,由 UNIX 的实现转为协议的事实标准

但也承认了 TCP 设计的一些不合理之处,比如 Buffer 大小选择, 比如 PSH 语义模糊.
## 实验结果(Evaluation)
本文没有实验部分
## 结论(Conclusion)
互联网架构在优先事项方面取得了巨大成功,广泛应用于商业和军事领域,同时催生了许多类似的架构.然而也暴露出了设计者的优先级与实际用户需求不一致的问题.虽然数据报在解决互联网的核心目标方面表现出色,但在解决次要目标时却存在问题.

采用数据包模型后,互联网层失去了一些有助于其实现目标的信息来源,可能会导致互联网层在某些方面的性能或功能方面受到限制.比如不可靠,无法保证顺序传输,没有状态信息,路由和转发问题,没有信息源等等.

最后作者还提出了关于未来互联网流式传输,软状态的一些构想,但时至今日似乎还是数据包的天下.

## 自己的思考

### 阅读本文的收获和感想
通读全文,作者思路很清晰文笔很流畅.围绕最早期的网络架构设计的初始目标,以及在此基础之上的其余目标逐层展开介绍,为了维持通信采用 fate-shareing 的设计,采用无状态的设计,以及后文对于数据包设计的解释,对于TCP流式传输设计的优劣之处讨论都非常值得思考.

作者也相当具有远见,当时看来很多尚未解决的问题(比如路由选择算法,流量计算)现如今都已经有了成熟的解决方案,大部分的协议(TCP HTTP SMTP)也都有数据包恢复机制以减小网络流量;主机端网络协议实现也已经由操作系统内核网络协议栈 + 网卡 + 网卡驱动负责了.
### 本文提出方案存在的缺陷和可能的改进方法
早期TCP 流式传输的设计存在缺陷,将一些将序列空间和主机的缓冲区管理算法相关联的方法纳入 TCP 中是正确的想法.当时的设计师们没能实现这一点.

采用数据包模型后,互联网层失去了一些有助于其实现目标的信息来源,可能会导致互联网层在某些方面的性能或功能方面受到限制.也带来了种种问题,比如不可靠,无法保证顺序传输,没有状态信息,路由和转发问题,没有信息源等等


## fate-shareing

fate-shareing 是一个工程设计哲学,关键是确保相关系统的部分要么一起失败,要么不失败.这个定义强调了关联部分之间的紧密联系,以确保它们在失败时保持一致

在网络领域,Fate-sharing 可以应用于确保网络中的各种组件或节点之间的状态一致性和可用性.如果某些部分共享他们的命运,这意味着它们要么一起成功,要么一起失败.这有助于确保系统在某些组件或节点发生故障时不会出现不一致的情况,从而提高了系统的可用性和可维护性.

这一概念的关键点在于,如果某个组件或节点无法正常工作,它的状态信息不应该被丢失,因为这可能会导致系统中的不一致性.因此,Fate-sharing 的目标是确保在失败时系统能够以一致的方式处理状态信息,以维护整个系统的一致性

## 参考

- [Fate-sharing](https://en.wikipedia.org/wiki/Fate-sharing)